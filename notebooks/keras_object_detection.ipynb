{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_object_detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kylehounslow/gdg_workshop/blob/master/notebooks/keras_object_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "PjXDcAQjkXVi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Object Detection using \"Black-Box\" YoloV3 trained on ImageNet  \n",
        "In this notebook we will leverage a pretrained object detection network [YOLOv3](https://pjreddie.com/darknet/yolo/).  \n",
        "In the [gdg_workshop repository](https://github.com/kylehounslow/gdg_workshop) I've written a few python modules to take care of the model setup so we can make predictions right away.   \n",
        "___\n",
        "Topics covered in this notebook:  \n",
        "* Importing code from Github into Colab  \n",
        "* Downloading imagery and video into Colab  \n",
        "* Object detection with YOLOv3  "
      ]
    },
    {
      "metadata": {
        "id": "XLDgxoh22Pqr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Make sure our runtime has a GPU attached usig `nvidia-smi` shell command"
      ]
    },
    {
      "metadata": {
        "id": "uspeHtUaKn1C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xkARyATJKDYd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Start by cloning the `gdg_workshop` repository to our colab instance and installing the required libraries"
      ]
    },
    {
      "metadata": {
        "id": "OUkrHPO6JTjB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf gdg_workshop && git clone --quiet https://github.com/kylehounslow/gdg_workshop.git\n",
        "!pip install --quiet -r gdg_workshop/requirements_colab.txt\n",
        "!pip --quiet install youtube-dl\n",
        "!apt-get -qq install ffmpeg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dPbL7upi0Rfy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cd gdg_workshop/ && git pull --quiet origin master\n",
        "!cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-PQV-UGhLf_R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import the YOLOV3 module and some other dependencies"
      ]
    },
    {
      "metadata": {
        "id": "ha2cvn9fpJsS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import youtube_dl\n",
        "from google.colab.files import download\n",
        "from gdg_workshop.models.keras_yolov3 import YOLOV3\n",
        "from gdg_workshop import util\n",
        "plt.style.use('default')\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SJFVWzntkiMq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Instatiate the detector  \n",
        "The `__init__` function for `YOLOV3` will take care of downloading the pretrained model weights and setting up the necessary variables for inference.  \n",
        "See code [here](https://github.com/kylehounslow/gdg_workshop/blob/master/models/keras_yolov3/src/yolo.py)"
      ]
    },
    {
      "metadata": {
        "id": "pclDZPz5qebA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "detector = YOLOV3()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e8XIJYCRKZFW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualize the YOLOV3 Model Architecture\n",
        "**Spoiler alert:** It is insane"
      ]
    },
    {
      "metadata": {
        "id": "y5_wHu_l30k3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from IPython.display import  HTML\n",
        "def strip_consts(graph_def, max_const_size=32):\n",
        "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
        "    strip_def = tf.GraphDef()\n",
        "    for n0 in graph_def.node:\n",
        "        n = strip_def.node.add() \n",
        "        n.MergeFrom(n0)\n",
        "        if n.op == 'Const':\n",
        "            tensor = n.attr['value'].tensor\n",
        "            size = len(tensor.tensor_content)\n",
        "            if size > max_const_size:\n",
        "                tensor.tensor_content = tf.compat.as_bytes(\"<stripped %d bytes>\"%size)\n",
        "    return strip_def\n",
        "  \n",
        "def rename_nodes(graph_def, rename_func):\n",
        "    res_def = tf.GraphDef()\n",
        "    for n0 in graph_def.node:\n",
        "        n = res_def.node.add() \n",
        "        n.MergeFrom(n0)\n",
        "        n.name = rename_func(n.name)\n",
        "        for i, s in enumerate(n.input):\n",
        "            n.input[i] = rename_func(s) if s[0]!='^' else '^'+rename_func(s[1:])\n",
        "    return res_def\n",
        "  \n",
        "def show_graph(graph_def, max_const_size=32):\n",
        "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
        "    if hasattr(graph_def, 'as_graph_def'):\n",
        "        graph_def = graph_def.as_graph_def()\n",
        "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
        "    code = \"\"\"\n",
        "        <script>\n",
        "          function load() {{\n",
        "            document.getElementById(\"{id}\").pbtxt = {data};\n",
        "          }}\n",
        "        </script>\n",
        "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
        "        <div style=\"height:600px\">\n",
        "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
        "        </div>\n",
        "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
        "  \n",
        "    iframe = \"\"\"\n",
        "        <iframe seamless style=\"width:800px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
        "    \"\"\".format(code.replace('\"', '&quot;'))\n",
        "    display(HTML(iframe))\n",
        "show_graph(tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9mdrNy06pB6M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define a function to download image from URL and run detection\n",
        " The following defines a form widget for user input, downloads image and runs inference "
      ]
    },
    {
      "metadata": {
        "id": "oB_IRRv9MoE3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title ## Detect objects from image url\n",
        "#@markdown ### Enter an image URL:\n",
        "url = \"https://i.ytimg.com/vi/gcI1BP1SlCk/maxresdefault.jpg\" #@param {type:\"string\"}\n",
        "img = util.download_image(url)\n",
        "from PIL import Image\n",
        "detections = detector.detect(image=img)\n",
        "img_draw = detector.draw_detections(img, detections)\n",
        "plt.figure(figsize=(18,12))\n",
        "plt.imshow(img_draw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KkZ6tv7Wklni",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define a function to upload an image and run detection "
      ]
    },
    {
      "metadata": {
        "id": "h_tOmd-5JaPT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "from google.colab import files\n",
        "def upload_detect_show(detector):\n",
        "    uploaded_files = files.upload()\n",
        "    image_filenames = list(uploaded_files.keys())\n",
        "    for image_filename in image_filenames:\n",
        "        image = Image.open(image_filename)\n",
        "        detections = detector.detect(image=image)\n",
        "        img_draw = detector.draw_detections(image, detections)\n",
        "        return Image.fromarray(img_draw)\n",
        "upload_detect_show(detector=detector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HQEGMm2-Blv3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Images are a bit boring... Let's try on video!"
      ]
    },
    {
      "metadata": {
        "id": "lmQ5yT9XWy8Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download video from a YouTube url"
      ]
    },
    {
      "metadata": {
        "id": "kWg9cSDnBrrL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title ## Detect objects from video url\n",
        "#@markdown ### Enter a video URL:\n",
        "video_url = \"https://www.youtube.com/watch?v=brYP3XVf_sM\" #@param {type:\"string\"}\n",
        "video_filename = 'video.mp4'\n",
        "!rm -f $video_filename\n",
        "ydl_opts = {\n",
        "    'outtmpl' : video_filename,\n",
        "    'nooverwrites': False}\n",
        "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "  ydl.download([video_url])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0oh9V6o-W7jp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Use OpenCV (ffmpeg backend) to open video, loop through frames and perform detection.  \n",
        "To save output video, we'll save individual frames as we perform detection.  \n",
        "Once complete, compile video from frames afterward using `frames_to_video()` (found in [util](https://github.com/kylehounslow/gdg_workshop/blob/master/util.py))"
      ]
    },
    {
      "metadata": {
        "id": "MahGosVmCLrV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "video_basename, video_ext = os.path.splitext(video_filename)\n",
        "output_frames_dir = os.path.basename(video_basename) + '_frames/'\n",
        "! rm -rf $output_frames_dir && mkdir $output_frames_dir\n",
        "vc = cv2.VideoCapture()\n",
        "vc.open(video_filename)\n",
        "frame_count = int(vc.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "video_fps = int(vc.get(cv2.CAP_PROP_FPS))\n",
        "plt.figure(figsize=(18,12))\n",
        "curr_frame = 0\n",
        "MAX_FRAMES = 1200  # limit our frames if video is quite long\n",
        "for frame_pos in tqdm(range(frame_count)):\n",
        "  _, img = vc.read()\n",
        "  detections = detector.detect(image=cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "  img_draw = detector.draw_detections(img, detections)\n",
        "  img_filename = os.path.join(output_frames_dir, 'frame{}.jpg'.format(curr_frame))\n",
        "  cv2.imwrite(img_filename, img_draw)\n",
        "  curr_frame += 1\n",
        "  if curr_frame > MAX_FRAMES:\n",
        "    vc.release()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yOHjqqnqhX6w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TODO: SUPPORT mp4 video output"
      ]
    },
    {
      "metadata": {
        "id": "uXD5S7bAhzg-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_video_filename = './output.mkv'\n",
        "!rm -f $output_video_filename\n",
        "util.frames_to_video(input_dir=output_frames_dir,\n",
        "                    output_file=output_video_filename, # NOTE: only mkv output supported at the moment. TODO: mp4\n",
        "                    fps=video_fps)\n",
        "download(output_video_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8wq1y5xq5290",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}